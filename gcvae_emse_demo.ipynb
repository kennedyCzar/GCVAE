{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized-Controllable Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#------------------basic dependencies --------------------\n",
    "seed = 42\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow_datasets as tfds\n",
    "from train_gcvae_2d import train_gcvae as gcvae #change this to train_gcvae_2d if you are working with GCVAE\n",
    "#----import trainer for distributed training\n",
    "#from train_gcvae_distrib import train_gcvae_distrib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import plot_latent_space, compute_metric, model_saver, model_saver_2d\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "import seaborn as sns\n",
    "#set random seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare path\n",
    "path = os.getcwd()\n",
    "\n",
    "#import data\n",
    "datatype = \"mnist\"\n",
    "\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() #load data\n",
    "N, L, M = x_train.shape #extract features of the data\n",
    "x_train = x_train.reshape(-1, L, M, 1).astype('float32') / x_train.max() #normalize training data\n",
    "x_train, _ = train_test_split(x_train, test_size = .999, random_state = 42) #split into train/test keeping only small fraction\n",
    "x_test = x_test.reshape(-1, L, M, 1).astype('float32') / x_train.max() #normalize test data\n",
    "x_test, _ = train_test_split(x_test, test_size = .992, random_state = 42) #split into train/test keeping only small fraction\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train) #convert data into tensor\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "#test data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
